# Project Plan: CLI Database Tool Integration

This project adds a new CLI utility within this repository to manage PostgreSQL databases. The CLI lives in `dbtool.go` and is guarded by the build tag `dbtool` to avoid conflicting with the existing `env-anonymizer` main package.

## Objectives

- Provide commands to list, dump, import, reset databases, and run ad-hoc SQL queries.
- Keep existing binaries unaffected by default `go build`.

## Build/Run

- Build default repo (env-anonymizer only):
  - `go build ./...`

- Run dbtool directly:
  - `go run -tags dbtool dbtool.go <command> ...`

- Build a dbtool binary:
  - `go build -tags dbtool -o dbtool dbtool.go`

### Verbose diagnostics

- Use `-v` or `--verbose` as a global flag to print diagnostics about configuration resolution.
- When enabled:
  - `dbtool.go` prints which `.env` files were found and applied, and how `DBTOOL_CONFIG_FILE` is resolved when relative.
  - `utility/dbtool/database.go` prints which `config.ini` path is used and when it is read.
  - `usage()` shows a Global flags section.

## Commands

- `database list` (aliases: `db list`, `db ls`)
  - Lists non-template databases.

- `database dump <dbname> <filepath> [--structure-only]` (aliases: `db dump`, `db export`)
  - Dumps database to a file using `pg_dump`.
  - Use `--structure-only` to dump schema only.

- `database import <dbname> <filepath> [--overwrite]` (aliases: `db import`, `db load`)
  - Imports SQL from a file using `psql -f`.
  - Use `--overwrite` to reset schema first.

- `database reset <dbname> [--noconfirm]` (aliases: `db reset`, `db wipe`)
  - Drops and recreates the `public` schema.
  - Confirmation required unless `--noconfirm`.

- `table list [<dbname>] [--schema=<schema>]` (aliases: `tables list`, `tables ls`)
  - Lists tables from `information_schema.tables`.
  - If no schema is provided, excludes system schemas (`pg_catalog`, `information_schema`).
  - `<dbname>` is optional; if omitted, defaults to `DB_NAME` or the database name parsed from `DATABASE_URL`.

- `query <dbname> --query="<sql>" [--json]` (alias: `q`)
  - Runs a SQL statement.
  - If `SELECT`, prints rows; `--json` outputs JSON.
  - If non-`SELECT`, executes and prints `OK` on success.

- `help [command] [subcommand]`
  - Shows summary or detailed usage, e.g., `help database dump`, `help q`.

## Configuration

`dbtool.go` loads Postgres connection info from:
`~/.config/<current-folder-name>/config.ini` in section `[default]` with keys:
- `DB_HOST`, `DB_PORT`, `DB_NAME`, `DB_USER`, `DB_PASSWORD`, `DB_SSLMODE`, `DB_MIGRATIONS_DIR`
- `DATABASE_URL` (optional DSN). If provided (e.g., `postgres://...`), it takes precedence over the discrete fields above.

Environment variables are also read as fallback for each key (e.g., `DB_HOST`, `DB_PORT`, and `DATABASE_URL`).

Defaults:
- `DB_SSLMODE=disabled` if not set
- `DB_PORT=5432` if not set

Xata support:
- If `DATABASE_URL` is set to a Xata HTTPS workspace URL (e.g., `https://<workspace>.xata.sh/db/<db>`), the tool will return a helpful error. Use Xata's PostgreSQL-compatible DSN instead (e.g., `postgres://...`) for connections, dumps, and imports.

## External Dependencies

- Requires `pg_dump` and `psql` available on PATH for dump/import.

## Next Steps

- Add nicer tabular output for `query` when not JSON.
- Optional flags for `dump`/`import` to control format (custom, directory).
- Add first-class helper to transform Xata HTTPS URL to its Postgres DSN (if/when Xata provides a deterministic mapping or via API).
- Unit tests for helper functions (where feasible without live DB).

## Recent Fixes

- For `query` non-row statements (e.g., DDL like `CREATE EXTENSION`) some providers could return a driver-level error such as `unexpected ReadyForQuery`. The implementation in `utility/dbtool/database.go` now detects this error from `db.Exec()` and safely falls back to invoking `psql -c` via new helper `RunPSQLInline()`.
- Xata compatibility: some Xata Postgres DSNs may reject `db.Ping()` despite allowing subsequent queries. We now detect Xata Postgres DSNs (host contains `xata.sh`) and skip `Ping()` in `ConnectDB` and `ConnectDBAs`, letting actual operations surface errors. This restores query functionality when using Xata branch-aware DSNs.

---

# New: Shared DB Config + Public IP CLI

## `utility/dbconf/`

- **Purpose**: Shared module to load `.env` and database config for all tools.
- **Behavior**:
  - Walks up from CWD to repo root, applying all `.env` files in order (like `dbtool.go`).
  - Resolves `DBTOOL_CONFIG_FILE` relative to each `.env` when not absolute.
  - Loads from `~/.config/<cwd>/config.ini` if no `DBTOOL_CONFIG_FILE`.
  - Supports discrete `DB_*` keys and `DATABASE_URL` with precedence identical to `dbtool`.
  - Exposes `DefaultDBName()`, `ConnectDB()`, `ConnectDBAs()`.

## `utility/publicip/`

- **Purpose**: Fetch external/public IP and optionally store/sync it.
- **Flags**:
  - `-ipv4` / `-ipv6`: family selection.
  - `-timeout`: overall fetch timeout.
  - `-store`: persist to DB (keeps `last_use_at` NULL for current IP; closes previous current).
  - `-db`: override DB name; default resolved via `dbconf.DefaultDBName()`.
  - `--sync-cf` (alias `--check-cf` deprecated): sync Cloudflare A records to current stored IP.
  - `--cf-host`: root host to manage (default `brain.portnumber53.com`).
  - `--cf-timeout`: Cloudflare API timeout (default 20s). Retries with backoff are enabled for updates.
- **Cloudflare**:
  - Requires `CLOUDFLARE_API_KEY` (API Token) with Zone:Read, DNS:Edit on the target zone.
  - Updates A records: `<cf-host>`, `*.stage.<zone>`, `*.dev.<zone>`.
- **Providers**: Queries multiple public IP providers in parallel with fallbacks.

## Schema for IP History

```sql
CREATE TABLE IF NOT EXISTS public.public_ip_history (
  ip inet PRIMARY KEY,
  first_use_at timestamptz NOT NULL DEFAULT now(),
  last_use_at timestamptz
);
```

Semantics: `last_use_at` remains NULL while the IP is current; set to `now()` when a new IP becomes current.

## Scheduling via systemd

- Unit files in `systemd/`:
  - `publicip.service`: oneshot service that runs `./bin/publicip --store --sync-cf --cf-timeout 40s` in the repo directory.
  - `publicip.timer`: runs on boot after 2 minutes and every 15 minutes thereafter; `Persistent=true` ensures missed runs execute after downtime.
- Build binary first:
```bash
go build -o bin/publicip ./utility/publicip
```
- Install (as root):
```bash
sudo cp systemd/publicip.* /etc/systemd/system/
sudo systemctl daemon-reload
sudo systemctl enable --now publicip.timer
```

## Jenkins CI/CD

- A Jenkins Pipeline is defined in `Jenkinsfile` to:
  - Checkout repository
  - Build `utility/publicip` to `bin/publicip`
  - Deploy the binary via SSH/SCP to local server `crash` as user `grimlock` (passwordless SSH assumed)
  - Optionally start `publicip.service` if present
- Environment:
  - Jenkins agent must have Go available (1.21+)
  - SSH keys for the Jenkins user should allow `grimlock@crash` without a password
